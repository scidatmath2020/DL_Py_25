{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNktIasowdrg"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# INFERENCIA \"AUTO\"(regresión / binaria / multiclase)\n",
        "# Entradas:\n",
        "#   1) resultados.zip   (contiene modelo.keras + metadata.json)\n",
        "#   2) New_final.csv    (nuevos datos con las MISMAS features)\n",
        "# Salida:\n",
        "#   New_predicciones.csv (agrega columnas según el tipo de problema)\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# ----------------------------\n",
        "# 0) Config\n",
        "# ----------------------------\n",
        "ZIP_RESULTADOS = \"resultados.zip\"\n",
        "NEW_CSV = \"New_final.csv\"\n",
        "OUT_PRED = \"New_predicciones.csv\"\n",
        "\n",
        "EXTRACT_DIR = \"inferencia_artifacts\"\n",
        "os.makedirs(EXTRACT_DIR, exist_ok=True)\n",
        "\n",
        "# ----------------------------\n",
        "# 1) Descomprimir resultados\n",
        "# ----------------------------\n",
        "with zipfile.ZipFile(ZIP_RESULTADOS, \"r\") as z:\n",
        "    z.extractall(EXTRACT_DIR)\n",
        "\n",
        "model_path = os.path.join(EXTRACT_DIR, \"modelo.keras\")\n",
        "meta_path  = os.path.join(EXTRACT_DIR, \"metadata.json\")\n",
        "\n",
        "# ----------------------------\n",
        "# 2) Cargar modelo + metadata\n",
        "# ----------------------------\n",
        "model = keras.models.load_model(model_path)\n",
        "\n",
        "with open(meta_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    meta = json.load(f)\n",
        "\n",
        "n0_esperado = int(meta.get(\"n_features\", -1))\n",
        "\n",
        "# Umbral para binaria:\n",
        "alpha = meta.get(\"alpha\", None)\n",
        "if alpha is None:\n",
        "    alpha = meta.get(\"threshold\", 0.5)\n",
        "alpha = float(alpha)\n",
        "\n",
        "# ¿clase positiva crítica?\n",
        "clase_positiva_critica = meta.get(\"clase_positiva_critica\", None)\n",
        "if clase_positiva_critica is None:\n",
        "    clases_simetricas = bool(meta.get(\"clases_simetricas\", True))\n",
        "    clase_positiva_critica = (not clases_simetricas)\n",
        "else:\n",
        "    clase_positiva_critica = bool(clase_positiva_critica)\n",
        "\n",
        "metrica_principal = meta.get(\"metrica_principal\", None)\n",
        "if metrica_principal is None:\n",
        "    metrica_principal = \"Accuracy\" if not clase_positiva_critica else \"F1\"\n",
        "metrica_principal = str(metrica_principal)\n",
        "\n",
        "# ----------------------------\n",
        "# 3) Cargar nuevos datos\n",
        "# ----------------------------\n",
        "new = pd.read_csv(NEW_CSV)\n",
        "\n",
        "# Si viene target, se quita para inferencia\n",
        "if \"target\" in new.columns:\n",
        "    new_X = new.drop(columns=[\"target\"])\n",
        "else:\n",
        "    new_X = new.copy()\n",
        "\n",
        "# ----------------------------\n",
        "# 4) Validación mínima de columnas\n",
        "# ----------------------------\n",
        "if n0_esperado != -1 and new_X.shape[1] != n0_esperado:\n",
        "    raise ValueError(\n",
        "        f\"New_final.csv tiene {new_X.shape[1]} features, pero el modelo espera {n0_esperado}. \"\n",
        "        \"Asegúrate de aplicar el mismo preprocesamiento y tener las mismas columnas.\"\n",
        "    )\n",
        "\n",
        "non_numeric = [c for c in new_X.columns if not pd.api.types.is_numeric_dtype(new_X[c])]\n",
        "if non_numeric:\n",
        "    raise ValueError(\n",
        "        f\"Estas columnas no son numéricas: {non_numeric}. \"\n",
        "        \"New_final.csv debe venir ya preprocesado (solo numérico).\"\n",
        "    )\n",
        "\n",
        "X = new_X.astype(np.float32).values\n",
        "\n",
        "# ----------------------------\n",
        "# 5) Predicción cruda\n",
        "# ----------------------------\n",
        "y_raw = model.predict(X, verbose=0)\n",
        "\n",
        "# ----------------------------\n",
        "# 6) Detección automática del tipo de problema\n",
        "# ----------------------------\n",
        "out_shape = model.output_shape\n",
        "out_dim = int(out_shape[-1]) if isinstance(out_shape, tuple) else int(out_shape[0][-1])\n",
        "\n",
        "last_layer = model.layers[-1]\n",
        "act_name = None\n",
        "try:\n",
        "    act = getattr(last_layer, \"activation\", None)\n",
        "    act_name = act.__name__ if act is not None else None\n",
        "except Exception:\n",
        "    act_name = None\n",
        "\n",
        "def detect_task(out_dim: int, act_name: str | None) -> str:\n",
        "    act_name = (act_name or \"\").lower()\n",
        "    if out_dim == 1:\n",
        "        if \"sigmoid\" in act_name:\n",
        "            return \"binary_classification\"\n",
        "        return \"regression\"\n",
        "    else:\n",
        "        if \"softmax\" in act_name:\n",
        "            return \"multiclass_classification\"\n",
        "        return \"multiclass_classification\"\n",
        "\n",
        "task = detect_task(out_dim, act_name)\n",
        "\n",
        "print(\"=== Detección automática ===\")\n",
        "print(\"output_shape:\", model.output_shape)\n",
        "print(\"last_activation:\", act_name)\n",
        "print(\"task_detected:\", task)\n",
        "\n",
        "if task == \"binary_classification\":\n",
        "    print(\"\\n=== Configuración binaria desde metadata ===\")\n",
        "    print(\"Alpha empleado (umbral):\", alpha)\n",
        "    print(\"¿Clase positiva (1) crítica?:\", clase_positiva_critica)\n",
        "    print(\"Métrica principal:\", metrica_principal)\n",
        "\n",
        "# ----------------------------\n",
        "# Helpers multiclase\n",
        "# ----------------------------\n",
        "def stable_softmax(z: np.ndarray) -> np.ndarray:\n",
        "    # z: (n, C)\n",
        "    z = z - np.max(z, axis=1, keepdims=True)\n",
        "    ez = np.exp(z)\n",
        "    return ez / np.sum(ez, axis=1, keepdims=True)\n",
        "\n",
        "def get_index_to_class_from_meta(meta: dict, out_dim: int):\n",
        "    \"\"\"\n",
        "    Devuelve:\n",
        "      - index_to_class: dict[int,int|str] o None si no existe\n",
        "      - classes_original: list en el orden interno 0..C-1 si se puede\n",
        "    \"\"\"\n",
        "    index_to_class = meta.get(\"index_to_class\", None)\n",
        "    classes_original = None\n",
        "\n",
        "    if isinstance(index_to_class, dict) and len(index_to_class) > 0:\n",
        "        # keys vienen como str en json, los pasamos a int\n",
        "        tmp = {}\n",
        "        for k, v in index_to_class.items():\n",
        "            try:\n",
        "                ki = int(k)\n",
        "            except Exception:\n",
        "                continue\n",
        "            tmp[ki] = v\n",
        "        index_to_class = tmp\n",
        "\n",
        "        # Armamos lista en orden 0..C-1 si están todos\n",
        "        ok = all((i in index_to_class) for i in range(out_dim))\n",
        "        if ok:\n",
        "            classes_original = [index_to_class[i] for i in range(out_dim)]\n",
        "        return index_to_class, classes_original\n",
        "\n",
        "    # Fallback: si existe classes_original_train como lista y coincide con out_dim\n",
        "    classes_original_train = meta.get(\"classes_original_train\", None)\n",
        "    if isinstance(classes_original_train, list) and len(classes_original_train) == out_dim:\n",
        "        classes_original = classes_original_train\n",
        "        index_to_class = {i: classes_original[i] for i in range(out_dim)}\n",
        "        return index_to_class, classes_original\n",
        "\n",
        "    return None, None\n",
        "\n",
        "# ----------------------------\n",
        "# 7) Post-procesamiento según tarea + guardar\n",
        "# ----------------------------\n",
        "out = new.copy()\n",
        "\n",
        "if task == \"regression\":\n",
        "    y_pred = np.asarray(y_raw).reshape(-1)\n",
        "    out[\"y_pred\"] = y_pred\n",
        "\n",
        "elif task == \"binary_classification\":\n",
        "    y_prob = np.asarray(y_raw).reshape(-1)\n",
        "    y_class = (y_prob >= alpha).astype(int)\n",
        "    out[\"y_prob\"] = y_prob\n",
        "    out[\"y_class\"] = y_class\n",
        "\n",
        "elif task == \"multiclass_classification\":\n",
        "    y_scores = np.asarray(y_raw)\n",
        "\n",
        "    if y_scores.ndim != 2 or y_scores.shape[1] != out_dim:\n",
        "        raise ValueError(f\"Salida inesperada para multiclase. shape={y_scores.shape}, out_dim={out_dim}\")\n",
        "\n",
        "    # 1) Asegurar \"probabilidades\": si no es softmax, construimos pseudo-prob con softmax estable\n",
        "    if (act_name or \"\").lower().find(\"softmax\") >= 0:\n",
        "        y_prob = y_scores\n",
        "    else:\n",
        "        y_prob = stable_softmax(y_scores)\n",
        "\n",
        "    # 2) Predicción por índice interno\n",
        "    y_idx = y_prob.argmax(axis=1).astype(int)\n",
        "    out[\"y_class_index\"] = y_idx\n",
        "\n",
        "    # 3) Mapear a clase original (si metadata lo permite)\n",
        "    index_to_class, classes_original = get_index_to_class_from_meta(meta, out_dim)\n",
        "\n",
        "    if index_to_class is not None:\n",
        "        # OJO: v puede ser int o str; lo dejamos como viene\n",
        "        y_class_original = np.array([index_to_class[int(i)] for i in y_idx], dtype=object)\n",
        "        out[\"y_class\"] = y_class_original\n",
        "    else:\n",
        "        # fallback: dejamos índice\n",
        "        out[\"y_class\"] = y_idx\n",
        "\n",
        "    # 4) Confianza (prob del top-1)\n",
        "    out[\"y_conf\"] = y_prob.max(axis=1)\n",
        "\n",
        "    # 5) Probabilidades por clase: nombrar con la clase original si existe, si no con índice\n",
        "    if classes_original is not None:\n",
        "        # ejemplo: prob_c1, prob_c2, prob_c3... (o prob_c5, prob_c7 en glass)\n",
        "        for j, lab in enumerate(classes_original):\n",
        "            out[f\"prob_c{lab}\"] = y_prob[:, j]\n",
        "    else:\n",
        "        for j in range(out_dim):\n",
        "            out[f\"prob_c{j}\"] = y_prob[:, j]\n",
        "\n",
        "    # 6) Top-3 (útil y barato)\n",
        "    TOPK = 3 if out_dim >= 3 else out_dim\n",
        "    top_idx = np.argsort(-y_prob, axis=1)[:, :TOPK]\n",
        "    top_prob = np.take_along_axis(y_prob, top_idx, axis=1)\n",
        "\n",
        "    if index_to_class is not None:\n",
        "        # mapear índices top a etiquetas originales\n",
        "        top_lab = np.vectorize(lambda i: index_to_class[int(i)], otypes=[object])(top_idx)\n",
        "        for k in range(TOPK):\n",
        "            out[f\"top{k+1}_class\"] = top_lab[:, k]\n",
        "            out[f\"top{k+1}_prob\"] = top_prob[:, k]\n",
        "    else:\n",
        "        for k in range(TOPK):\n",
        "            out[f\"top{k+1}_class\"] = top_idx[:, k]\n",
        "            out[f\"top{k+1}_prob\"] = top_prob[:, k]\n",
        "\n",
        "else:\n",
        "    raise ValueError(f\"Tarea no soportada: {task}\")\n",
        "\n",
        "out.to_csv(OUT_PRED, index=False)\n",
        "print(f\"\\n✔ Predicciones guardadas en: {OUT_PRED}\")\n",
        "print(out.head())\n"
      ]
    }
  ]
}