{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa08af3-0190-4db4-9fb6-1b2abf660447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CLASIFICACIÓN BINARIA\n",
    "# Entradas:\n",
    "#   1) artifacts_preprocesamiento.zip   (contiene las tablas procesadas)\n",
    "# Salida:\n",
    "#   resultados.zip (historial de entrenamiento, metadatos y modelo final)\n",
    "# ============================================================\n",
    "\n",
    "# ============================================================\n",
    "# Diseñador de red para clasificación binaria basado en heurísticas\n",
    "# ============================================================\n",
    "\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DisenoRedBinaria:\n",
    "    capas: List[int]\n",
    "    P: int\n",
    "    rho: float\n",
    "    l2: float\n",
    "    dropouts: List[float]\n",
    "    patience: int\n",
    "    min_delta: float\n",
    "    max_epochs: int\n",
    "\n",
    "\n",
    "def clip(x: float, lo: float, hi: float) -> float:\n",
    "    return max(lo, min(hi, x))\n",
    "\n",
    "\n",
    "def estimar_parametros(n0: int, capas: List[int]) -> int:\n",
    "    \"\"\"\n",
    "    Cuenta parámetros de una red densa:\n",
    "      - incluye sesgos en cada capa\n",
    "      - incluye capa de salida (1 neurona)\n",
    "    \"\"\"\n",
    "    if not capas:\n",
    "        return 0\n",
    "\n",
    "    P = (n0 + 1) * capas[0]\n",
    "    for i in range(1, len(capas)):\n",
    "        P += (capas[i - 1] + 1) * capas[i]\n",
    "    P += (capas[-1] + 1) * 1\n",
    "    return int(P)\n",
    "\n",
    "\n",
    "def disenar_red_binaria(\n",
    "    d: int,\n",
    "    n0: int,\n",
    "    *,\n",
    "    k: int = 10,\n",
    "    c1: float = 2.0,\n",
    "    r: float = 0.5,\n",
    "    n_min: int = 8,\n",
    "    L_max: int = 4,\n",
    ") -> DisenoRedBinaria:\n",
    "    \"\"\"\n",
    "    Heurística análoga a la de regresión:\n",
    "      - d  : número de muestras (train)\n",
    "      - n0 : número de variables de entrada\n",
    "    Devuelve:\n",
    "      - DisenoRedBinaria\n",
    "    \"\"\"\n",
    "\n",
    "    # 0. Tope adaptativo de ancho (según tamaño de muestra)\n",
    "    n_max = min(1024, max(64, math.floor(0.25 * d)))\n",
    "\n",
    "    # 1. Verificación mínima de viabilidad (suave)\n",
    "    if d < 2 * n0:\n",
    "        raise ValueError(\"Dataset muy pequeño: alto riesgo de sobreajuste\")\n",
    "\n",
    "    # 2. Presupuesto total de parámetros\n",
    "    P_max = math.floor(k * d)\n",
    "\n",
    "    # 3. Tamaño de la primera capa oculta (capado por presupuesto y por n_max)\n",
    "    n1_cap_presupuesto = math.floor(P_max / (n0 + 1))\n",
    "    n1 = min(math.floor(c1 * n0), n1_cap_presupuesto, n_max)\n",
    "\n",
    "    if n1 < n_min:\n",
    "        raise ValueError(\"Presupuesto insuficiente: no se puede ni una capa >= n_min\")\n",
    "\n",
    "    capas = [int(n1)]\n",
    "\n",
    "    # 4. Construcción iterativa de capas ocultas (embudo)\n",
    "    while True:\n",
    "        if len(capas) >= L_max:\n",
    "            break\n",
    "\n",
    "        n_prev = capas[-1]\n",
    "        n_new = math.floor(r * n_prev)\n",
    "\n",
    "        if n_new < n_min:\n",
    "            break\n",
    "\n",
    "        n_new = min(n_new, n_max)\n",
    "        capas.append(int(n_new))\n",
    "\n",
    "    # 5. Estimación de parámetros (incluye sesgos y salida)\n",
    "    P = estimar_parametros(n0, capas)\n",
    "\n",
    "    # 6. Validación de complejidad (recorte iterativo)\n",
    "    while P > P_max:\n",
    "        if len(capas) > 1:\n",
    "            capas.pop()\n",
    "        else:\n",
    "            n_old = capas[0]\n",
    "            capas[0] = math.floor(0.9 * capas[0])  # reducción suave\n",
    "            if capas[0] >= n_old:\n",
    "                capas[0] = n_old - 1               # garantiza progreso\n",
    "            if capas[0] < n_min:\n",
    "                raise ValueError(\"Presupuesto insuficiente: no cabe una capa >= n_min\")\n",
    "\n",
    "        P = estimar_parametros(n0, capas)\n",
    "\n",
    "    # ========================================================\n",
    "    # 7. HIPERPARÁMETROS DE REGULARIZACIÓN (L2, Dropout, ES)\n",
    "    # ========================================================\n",
    "\n",
    "    # 7.1 Ocupación del presupuesto\n",
    "    rho = P / P_max if P_max > 0 else 1.0\n",
    "\n",
    "    # -------- Dropout base por tamaño de muestra --------\n",
    "    if d < 2000:\n",
    "        drop_base = 0.35\n",
    "    elif d < 20000:\n",
    "        drop_base = 0.25\n",
    "    else:\n",
    "        drop_base = 0.15\n",
    "\n",
    "    # -------- Ajuste por ocupación rho --------\n",
    "    if rho >= 0.8:\n",
    "        drop = drop_base + 0.10\n",
    "    elif rho >= 0.4:\n",
    "        drop = drop_base\n",
    "    else:\n",
    "        drop = drop_base - 0.10\n",
    "    drop = clip(drop, 0.05, 0.50)\n",
    "\n",
    "    # Dropout por capa (más alto al inicio)\n",
    "    dropouts: List[float] = []\n",
    "    for i in range(1, len(capas) + 1):\n",
    "        di = drop * (1.0 - 0.15 * (i - 1))\n",
    "        di = clip(di, 0.05, 0.50)\n",
    "        dropouts.append(float(di))\n",
    "\n",
    "    # -------- L2 base por tamaño de muestra --------\n",
    "    if d < 2000:\n",
    "        l2_base = 1e-3\n",
    "    elif d < 20000:\n",
    "        l2_base = 3e-4\n",
    "    else:\n",
    "        l2_base = 1e-4\n",
    "\n",
    "    # -------- Ajuste por ocupación rho --------\n",
    "    if rho >= 0.8:\n",
    "        l2 = 3.0 * l2_base\n",
    "    elif rho >= 0.4:\n",
    "        l2 = 1.0 * l2_base\n",
    "    else:\n",
    "        l2 = 0.3 * l2_base\n",
    "    l2 = clip(l2, 1e-6, 3e-3)\n",
    "\n",
    "    # -------- Early stopping (patience) --------\n",
    "    if d < 2000:\n",
    "        patience = 20\n",
    "        max_epochs = 400\n",
    "    elif d < 20000:\n",
    "        patience = 15\n",
    "        max_epochs = 200\n",
    "    else:\n",
    "        patience = 10\n",
    "        max_epochs = 100\n",
    "\n",
    "    # (opcional) min_delta fijo simple\n",
    "    min_delta = 1e-4\n",
    "\n",
    "    return DisenoRedBinaria(\n",
    "        capas=capas,\n",
    "        P=int(P),\n",
    "        rho=float(rho),\n",
    "        l2=float(l2),\n",
    "        dropouts=dropouts,\n",
    "        patience=int(patience),\n",
    "        min_delta=float(min_delta),\n",
    "        max_epochs=int(max_epochs),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69f5748-e024-4f4b-9c82-b71629377c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Reproducibilidad (opcional)\n",
    "SEED = 7\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# ============================================================\n",
    "# 1) Abrir ZIP y leer train/val/test\n",
    "# ============================================================\n",
    "\n",
    "# Ruta al ZIP\n",
    "ZIP_PATH = \"artifacts_preprocesamiento.zip\"\n",
    "\n",
    "def read_csv_from_zip(zip_path: str, csv_name: str) -> pd.DataFrame:\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "        with z.open(csv_name) as f:\n",
    "            return pd.read_csv(f)\n",
    "\n",
    "train = read_csv_from_zip(ZIP_PATH, \"train_final.csv\")\n",
    "val   = read_csv_from_zip(ZIP_PATH, \"val_final.csv\")\n",
    "test  = read_csv_from_zip(ZIP_PATH, \"test_final.csv\")\n",
    "\n",
    "# ============================================================\n",
    "# 2) Definir target y armar X/y\n",
    "# ============================================================\n",
    "TARGET_COL = \"target\"\n",
    "\n",
    "X_train = train.drop(columns=[TARGET_COL])\n",
    "y_train = train[TARGET_COL].astype(int)\n",
    "\n",
    "X_val = val.drop(columns=[TARGET_COL])\n",
    "y_val = val[TARGET_COL].astype(int)\n",
    "\n",
    "X_test = test.drop(columns=[TARGET_COL])\n",
    "y_test = test[TARGET_COL].astype(int)\n",
    "\n",
    "# d y n0\n",
    "d  = X_train.shape[0]   # tamaño del entrenamiento\n",
    "n0 = X_train.shape[1]   # número de variables de entrada\n",
    "\n",
    "print(\"d =\", d)\n",
    "print(\"n0 =\", n0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61de9e4-3a22-492f-9fd6-0022ace47dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3) Configuración de evaluación (simetría vs clase crítica)\n",
    "# ============================================================\n",
    "#\n",
    "# True  -> clases simétricas -> optimizamos Accuracy\n",
    "# False -> clase 1 crítica   -> optimizamos F1 con Recall mínimo\n",
    "#\n",
    "# NOTA: Se usan en celdas 6 y 7 (alpha óptima + métricas finales)\n",
    "# ============================================================\n",
    "\n",
    "CLASES_SIMETRICAS = False\n",
    "RECALL_MIN = 0.5  # solo si CLASES_SIMETRICAS = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca6a935-7228-4ff3-ac0d-9e77c879db9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diseno = disenar_red_binaria(d, n0)\n",
    "print(diseno)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848afbe-f82e-4423-942c-1bf0ce56744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "capas     = diseno.capas\n",
    "l2_value  = diseno.l2\n",
    "dropouts  = diseno.dropouts\n",
    "patience  = diseno.patience\n",
    "min_delta = diseno.min_delta\n",
    "max_epochs= diseno.max_epochs\n",
    "\n",
    "def build_binary_mlp(n0: int, capas: list, l2_value: float, dropouts: list) -> keras.Model:\n",
    "    assert len(capas) == len(dropouts), \"capas y dropouts deben tener la misma longitud\"\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(n0,)))\n",
    "\n",
    "    for units, dr in zip(capas, dropouts):\n",
    "        model.add(\n",
    "            keras.layers.Dense(\n",
    "                units,\n",
    "                activation=\"relu\",\n",
    "                kernel_regularizer=keras.regularizers.l2(l2_value)\n",
    "            )\n",
    "        )\n",
    "        model.add(keras.layers.Dropout(dr))\n",
    "\n",
    "    # salida sigmoide (probabilidad clase 1)\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    return model\n",
    "\n",
    "model = build_binary_mlp(n0=n0, capas=capas, l2_value=l2_value, dropouts=dropouts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8875fe14-0478-464d-85e0-3a34898d8659",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        keras.metrics.BinaryAccuracy(name=\"accuracy\", threshold=0.5),\n",
    "    ],\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8710555a-5abb-4881-a31a-0fcf3b003b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5) Entrenar + validar (EarlyStopping)\n",
    "# ============================================================\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=patience,\n",
    "        min_delta=min_delta,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "BATCH_SIZE = 32  # puedes ajustar; lo dejo fijo\n",
    "\n",
    "history = model.fit(\n",
    "    X_train.astype(np.float32),\n",
    "    y_train.values,\n",
    "    validation_data=(X_val.astype(np.float32), y_val.values),\n",
    "    epochs=max_epochs,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2591b420-a66a-4790-b35e-3537ef70cd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6) Alpha óptima en validación + métricas finales en test\n",
    "# ============================================================\n",
    "\n",
    "def counts(y, yhat):\n",
    "    TP = ((y == 1) & (yhat == 1)).sum()\n",
    "    FP = ((y == 0) & (yhat == 1)).sum()\n",
    "    TN = ((y == 0) & (yhat == 0)).sum()\n",
    "    FN = ((y == 1) & (yhat == 0)).sum()\n",
    "    return int(TP), int(FP), int(TN), int(FN)\n",
    "\n",
    "def metrics_from_counts(TP, FP, TN, FN):\n",
    "    denom = TP + TN + FP + FN\n",
    "    acc = (TP + TN) / denom if denom else 0.0\n",
    "    rec = TP / (TP + FN) if (TP + FN) else 0.0\n",
    "    f1  = (2 * TP) / (2 * TP + FP + FN) if (2 * TP + FP + FN) else 0.0\n",
    "    return float(acc), float(rec), float(f1)\n",
    "\n",
    "def print_confusion_matrix(TP, FP, TN, FN, *, title=\"Matriz de confusión\"):\n",
    "    # Formato estándar:\n",
    "    #            Pred 0     Pred 1\n",
    "    # True 0       TN        FP\n",
    "    # True 1       FN        TP\n",
    "    print(f\"\\n{title}:\")\n",
    "    print(\"            Pred 0     Pred 1\")\n",
    "    print(f\"True 0     {TN:8d}  {FP:8d}\")\n",
    "    print(f\"True 1     {FN:8d}  {TP:8d}\")\n",
    "\n",
    "# ---- 6.1) Buscar alpha óptima en VALIDACIÓN ----\n",
    "p_val = model.predict(X_val.astype(np.float32), verbose=0).ravel()\n",
    "\n",
    "ALPHA_GRID = np.linspace(0.0, 1.0, 2001)  # paso 0.0005\n",
    "\n",
    "best_alpha = None\n",
    "best_val = -1.0\n",
    "\n",
    "fallback_alpha = None\n",
    "best_recall = -1.0\n",
    "\n",
    "for a in ALPHA_GRID:\n",
    "    yhat_val = (p_val >= a).astype(int)\n",
    "\n",
    "    TP, FP, TN, FN = counts(y_val.values, yhat_val)\n",
    "    acc, rec, f1 = metrics_from_counts(TP, FP, TN, FN)\n",
    "\n",
    "    if CLASES_SIMETRICAS:\n",
    "        # clases simétricas -> max accuracy\n",
    "        if acc > best_val:\n",
    "            best_alpha, best_val = float(a), float(acc)\n",
    "    else:\n",
    "        # clase 1 crítica -> max F1 con recall mínimo\n",
    "        if rec >= RECALL_MIN and f1 > best_val:\n",
    "            best_alpha, best_val = float(a), float(f1)\n",
    "\n",
    "        # fallback: el que logre el mejor recall aunque no cumpla el mínimo\n",
    "        if rec > best_recall:\n",
    "            fallback_alpha, best_recall = float(a), float(rec)\n",
    "\n",
    "ALPHA = best_alpha if best_alpha is not None else fallback_alpha\n",
    "\n",
    "# ---- Mensajes obligatorios solicitados ----\n",
    "metric_principal = \"Accuracy\" if CLASES_SIMETRICAS else \"F1\"\n",
    "\n",
    "print(\"\\n=== Configuración de decisión (binaria) ===\")\n",
    "print(\"Métrica principal:\", metric_principal)\n",
    "print(\"¿Clase positiva (1) crítica?:\", (not CLASES_SIMETRICAS))\n",
    "if not CLASES_SIMETRICAS:\n",
    "    print(\"Recall mínimo exigido:\", RECALL_MIN)\n",
    "print(\"Alpha empleado (umbral):\", ALPHA)\n",
    "\n",
    "# ---- 6.2) Métricas finales en TEST usando ALPHA ----\n",
    "p_test = model.predict(X_test.astype(np.float32), verbose=0).ravel()\n",
    "yhat_test = (p_test >= ALPHA).astype(int)\n",
    "\n",
    "TP, FP, TN, FN = counts(y_test.values, yhat_test)\n",
    "acc, rec, f1 = metrics_from_counts(TP, FP, TN, FN)\n",
    "\n",
    "test_metrics = {\n",
    "    \"TP\": TP, \"FP\": FP, \"TN\": TN, \"FN\": FN,\n",
    "    \"accuracy\": acc,\n",
    "    \"recall\": rec,\n",
    "    \"f1\": f1,\n",
    "}\n",
    "\n",
    "print_confusion_matrix(TP, FP, TN, FN, title=\"Matriz de confusión (TEST)\")\n",
    "# ---- Mostrar métricas como tabla ----\n",
    "print(\"\\nMétricas en test:\")\n",
    "print(\"-----------------------------------\")\n",
    "print(f\"{'Métrica':<15} | {'Valor':>10}\")\n",
    "print(\"-----------------------------------\")\n",
    "print(f\"{'Accuracy':<15} | {acc:10.4f}\")\n",
    "print(f\"{'Recall':<15} | {rec:10.4f}\")\n",
    "print(f\"{'F1':<15} | {f1:10.4f}\")\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "# ============================================================\n",
    "# 7) Guardar resultados y empaquetar ZIP final\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "OUT_DIR = \"salida_binaria\"\n",
    "ZIP_NAME = \"resultados.zip\"\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "metadata = {\n",
    "    \"n_samples_train\": int(d),\n",
    "    \"n_features\": int(n0),\n",
    "    \"architecture\": capas,\n",
    "    \"l2\": float(l2_value),\n",
    "    \"dropouts\": dropouts,\n",
    "    \"patience\": int(patience),\n",
    "    \"min_delta\": float(min_delta),\n",
    "    \"max_epochs\": int(max_epochs),\n",
    "\n",
    "    # --- claves para inferencia universal ---\n",
    "    \"alpha\": float(ALPHA),\n",
    "\n",
    "    # --- decisión / prioridad ---\n",
    "    \"clases_simetricas\": bool(CLASES_SIMETRICAS),\n",
    "    \"clase_positiva_critica\": bool(not CLASES_SIMETRICAS),\n",
    "    \"metrica_principal\": metric_principal,\n",
    "    \"recall_min\": None if CLASES_SIMETRICAS else float(RECALL_MIN),\n",
    "\n",
    "    # --- resultados finales ---\n",
    "    \"metrics_test\": test_metrics,\n",
    "    \"confusion_matrix_test\": {\n",
    "        \"TN\": TN, \"FP\": FP,\n",
    "        \"FN\": FN, \"TP\": TP\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(os.path.join(OUT_DIR, \"metadata.json\"), \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "# Guardar modelo (ya entrenado)\n",
    "model_path = os.path.join(OUT_DIR, \"modelo.keras\")\n",
    "model.save(model_path)\n",
    "\n",
    "# Guardar historial de entrenamiento (igual que regresión)\n",
    "history_path = os.path.join(OUT_DIR, \"historial_entrenamiento.csv\")\n",
    "pd.DataFrame(history.history).to_csv(history_path, index=False)\n",
    "\n",
    "# Empaquetar todo en ZIP\n",
    "with zipfile.ZipFile(ZIP_NAME, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for file in [model_path, history_path, os.path.join(OUT_DIR, \"metadata.json\")]:\n",
    "        zipf.write(file, arcname=os.path.basename(file))\n",
    "\n",
    "print(f\"\\n✔ ZIP generado correctamente: {ZIP_NAME}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
