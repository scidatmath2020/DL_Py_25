{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bacb63a-ec6c-459d-b694-9e06271c7b1e",
   "metadata": {},
   "source": [
    "![imagenes](logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37214719-5167-4496-8f5d-5e5a5a0b7e7a",
   "metadata": {},
   "source": [
    "# Entrenamiento, prueba y validación\n",
    "\n",
    "La práctica estándar en deep learning consiste en dividir el conjunto total de datos en dos subconjuntos:\n",
    "\n",
    "**Conjunto de entrenamiento (training set):** es el subconjunto de datos que se utiliza para ajustar los parámetros de la red neuronal. Aquí es donde el cerebro aprende.\n",
    "\n",
    "**Conjunto de prueba (test set):** es el subconjunto que se mantiene completamente separado y se utiliza exclusivamente para evaluar el rendimiento final del cerebro.\n",
    "\n",
    "Esta separación debe hacerse antes de entrenar la red neuronal, y debe mantenerse inviolable: jamás se deben usar los datos de prueba para ajustar el modelo. Solo así podemos obtener una estimación honesta de su capacidad de aprendizaje.\n",
    "\n",
    "<center>\n",
    "  <img src=\"im04.png\" style=\"width:500px; height:500px;\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de14c4a-2db3-42a9-8a77-e35774f43502",
   "metadata": {},
   "source": [
    "## Entrenamiento\n",
    "\n",
    "Durante el entrenamiento, el modelo utiliza los datos disponibles para ajustar sus parámetros internos. En una red neuronal, significa ajustar los pesos y sesgos mediante retropropagación. El objetivo es reducir el error de predicción en los datos conocidos.\n",
    "\n",
    "Pero aquí está la trampa: el objetivo del entrenamiento no es únicamente predecir bien los datos de entrenamiento, sino predecir bien datos que el modelo nunca ha visto. Entrenar bien no garantiza aprender bien.\n",
    "\n",
    "La división típica es entre un 70% u 80% para entrenamiento, y un 30% o 20% para prueba. Esta proporción puede variar dependiendo del tamaño del conjunto total. \n",
    "\n",
    "Si se dispone de muy pocos datos, usar una sola partición puede ser arriesgado. En esos casos, se recomienda usar técnicas como la **validación cruzada**, donde el conjunto de prueba rota, o el **bootstrap**, que crea muestras con reemplazo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dd38b8-9732-479a-b08f-26f148c904e6",
   "metadata": {},
   "source": [
    "## Validación cruzada\n",
    "\n",
    "La validación cruzada (cross-validation) en DL es una técnica de evaluación de modelos que permite estimar su capacidad de generalización, especialmente útil cuando se tienen conjuntos de datos limitados. Se aplica con adaptaciones debido al alto coste computacional.\n",
    "\n",
    "La idea principal es dividir los datos en $K$ particiones (folds), entrenar el modelo $K$ veces usando $K-1$ particiones como entrenamiento y 1 partición como validación, rotando la partición de validación cada vez.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f464bc69-0837-454c-bd8d-d3e6b86add26",
   "metadata": {},
   "source": [
    "<center>\n",
    "  <img src=\"im05.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6803fc1-d705-474c-b5b5-3403c8745c82",
   "metadata": {},
   "source": [
    "## Proceso de la validación cruzada\n",
    "\n",
    "Supongamos una arquitectura general $n_0-n_1-n_2-...-n_R-n_{out}$ con $p$ parámetros (ya sabemos cómo calcular $p$). Tomemos\n",
    "\n",
    "\n",
    "- $d$ datos en total (es decir, $d$ clientes).\n",
    "- Tamaño de batch $B$ (recuerda que $B=d$ es gradiente descendente; $B=1$ es gradiente estocástico y $1<B<d$ es minibatch).\n",
    "- $E$ épocas\n",
    "- Separación en entrenamiento y prueba de $0<e<1$ para entrenamiento (y $1-e$ para prueba)\n",
    "- $K$ particiones (folds) para la validación cruzada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9db7a26-47bf-462c-a639-9a350ca260c4",
   "metadata": {},
   "source": [
    "### 1. Separación estructural inicial\n",
    "\n",
    "Separamos en entrenamiento y prueba: $\\mathcal{D}_{train}$, con $|\\mathcal{D}_{train}|=e\\cdot d$, y $\\mathcal{D}_{test}$, con $|\\mathcal{D}_{test}|=(1-e)\\cdot d$. El conjunto $\\mathcal{D}_{test}$ **no vuelve a tocarse**.\n",
    "\n",
    "### 2. Construcción de los folds\n",
    "\n",
    "Partimos $\\mathcal{D}_{train}$ en $K$ folds:\n",
    "$$\\mathcal{D}_{train}=P_1\\cup P_2\\cup P_3\\cup...\\cup P_K\\mbox{ con }|P_k|=\\frac{e\\cdot d}{K}$$\n",
    "\n",
    "Cada $P_k$ tiene el $\\frac{100}{K}\\%$ de la tabla de entrenamiento.\n",
    "\n",
    "### 3. Ciclo de la validación cruzada\n",
    "\n",
    "Para cada $k\\in\\{1,2,...,K\\}$ se definen:\n",
    "- Entrenamiento del fold:\n",
    " $$\\mathcal{D}_{train}^{(k)}=\\mathcal{D}_{train}\\backslash P_k$$\n",
    "- Validación del fold:\n",
    " $$\\mathcal{D}_{val}^{(k)}=P_k$$\n",
    "\n",
    "### 4. ENTRENAMIENTO\n",
    "\n",
    "Para cada época $e\\in\\{1,2,...,E\\}$:\n",
    "1. Se reordena $\\mathcal{D}_{train}^{(k)}$\n",
    "2. Se parte en minibatches de tamaño $B$\n",
    "3. Para cada minibatch\n",
    "   - Propagación hacia adelante\n",
    "   - Cálculo de la función de pérdida\n",
    "   - Propagación hacia atrás\n",
    "   - Actualización de los $p$ parámetros\n",
    "\n",
    "### 5. Evaluación del fold\n",
    "\n",
    "Al terminar las $E$ épocas, se calcula la **pérdida de validación** $$\\mathcal{L}_{val}^{(k)}=\\mathcal{L}(\\mathcal{D}_{val}^{(k)})$$\n",
    "\n",
    "### 6. Resultado de la validación cruzada\n",
    "\n",
    "Después de los $K$ folds: $$\\mathcal{L}_{CV}=\\frac{1}{K}\\sum_{k=1}^K\\mathcal{L}_{val}^{(k)}$$\n",
    "\n",
    "Este valor se usa para comparar arquitecturas, regularización, elegir hiperparámetros ($\\eta$, $B$, $E$) o detectar sobreajuste.\n",
    "\n",
    "### 7. Paso final (fuera de la CV)\n",
    "\n",
    "Una vez tomada la decisión \n",
    "1. Se reentrena la red desde cero usando todo $\\mathcal{D}_{train}$\n",
    "2. Se evalúa una sola vez en $\\mathcal{D}_{test}$ y se obtiene $\\mathcal{L}_{test}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4988e974-6063-4db8-845a-997639ac76ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
