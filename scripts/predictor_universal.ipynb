{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k_BxvPbviSx"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# INFERENCIA \"AUTO\"(regresión / binaria / multiclase)\n",
        "# Entradas:\n",
        "#   1) resultados.zip   (contiene modelo.keras + metadata.json)\n",
        "#   2) New_final.csv    (nuevos datos con las MISMAS features)\n",
        "# Salida:\n",
        "#   New_predicciones.csv (agrega columnas según el tipo de problema)\n",
        "#\n",
        "# Detección automática:\n",
        "#   - Regresión:     salida (None, 1) y última activación ~ linear\n",
        "#   - Binaria:       salida (None, 1) y última activación ~ sigmoid\n",
        "#   - Multiclase:    salida (None, C) con C>1 y última activación ~ softmax\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# ----------------------------\n",
        "# 0) Config\n",
        "# ----------------------------\n",
        "ZIP_RESULTADOS = \"resultados.zip\"\n",
        "NEW_CSV = \"New_final.csv\"\n",
        "OUT_PRED = \"New_predicciones.csv\"\n",
        "\n",
        "EXTRACT_DIR = \"inferencia_artifacts\"\n",
        "os.makedirs(EXTRACT_DIR, exist_ok=True)\n",
        "\n",
        "# ----------------------------\n",
        "# 1) Descomprimir resultados\n",
        "# ----------------------------\n",
        "with zipfile.ZipFile(ZIP_RESULTADOS, \"r\") as z:\n",
        "    z.extractall(EXTRACT_DIR)\n",
        "\n",
        "model_path = os.path.join(EXTRACT_DIR, \"modelo.keras\")\n",
        "meta_path  = os.path.join(EXTRACT_DIR, \"metadata.json\")\n",
        "\n",
        "# ----------------------------\n",
        "# 2) Cargar modelo + metadata\n",
        "# ----------------------------\n",
        "model = keras.models.load_model(model_path)\n",
        "\n",
        "with open(meta_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    meta = json.load(f)\n",
        "\n",
        "n0_esperado = int(meta.get(\"n_features\", -1))\n",
        "# Umbral opcional (si lo guardaste alguna vez). Si no, 0.5.\n",
        "threshold = float(meta.get(\"threshold\", 0.5))\n",
        "\n",
        "# ----------------------------\n",
        "# 3) Cargar nuevos datos\n",
        "# ----------------------------\n",
        "new = pd.read_csv(NEW_CSV)\n",
        "\n",
        "# Si viene target, se quita para inferencia (aunque dijiste que no hay conflicto)\n",
        "if \"target\" in new.columns:\n",
        "    new_X = new.drop(columns=[\"target\"])\n",
        "else:\n",
        "    new_X = new.copy()\n",
        "\n",
        "# ----------------------------\n",
        "# 4) Validación mínima de columnas\n",
        "# ----------------------------\n",
        "if n0_esperado != -1 and new_X.shape[1] != n0_esperado:\n",
        "    raise ValueError(\n",
        "        f\"New_final.csv tiene {new_X.shape[1]} features, pero el modelo espera {n0_esperado}. \"\n",
        "        \"Asegúrate de aplicar el mismo preprocesamiento y tener las mismas columnas.\"\n",
        "    )\n",
        "\n",
        "non_numeric = [c for c in new_X.columns if not pd.api.types.is_numeric_dtype(new_X[c])]\n",
        "if non_numeric:\n",
        "    raise ValueError(\n",
        "        f\"Estas columnas no son numéricas: {non_numeric}. \"\n",
        "        \"New_final.csv debe venir ya preprocesado (solo numérico).\"\n",
        "    )\n",
        "\n",
        "X = new_X.astype(np.float32).values\n",
        "\n",
        "# ----------------------------\n",
        "# 5) Predicción cruda\n",
        "# ----------------------------\n",
        "y_raw = model.predict(X, verbose=0)\n",
        "\n",
        "# ----------------------------\n",
        "# 6) Detección automática del tipo de problema\n",
        "# ----------------------------\n",
        "# Dimensión de salida (None, out_dim)\n",
        "out_shape = model.output_shape\n",
        "out_dim = int(out_shape[-1]) if isinstance(out_shape, tuple) else int(out_shape[0][-1])\n",
        "\n",
        "# Activación de la última capa (si existe)\n",
        "last_layer = model.layers[-1]\n",
        "act_name = None\n",
        "try:\n",
        "    act = getattr(last_layer, \"activation\", None)\n",
        "    act_name = act.__name__ if act is not None else None\n",
        "except Exception:\n",
        "    act_name = None\n",
        "\n",
        "def detect_task(out_dim: int, act_name: str | None) -> str:\n",
        "    act_name = (act_name or \"\").lower()\n",
        "    if out_dim == 1:\n",
        "        if \"sigmoid\" in act_name:\n",
        "            return \"binary_classification\"\n",
        "        # si no es sigmoid, lo tratamos como regresión (lineal u otra)\n",
        "        return \"regression\"\n",
        "    else:\n",
        "        # C>1\n",
        "        if \"softmax\" in act_name:\n",
        "            return \"multiclass_classification\"\n",
        "        # fallback: si sale vector, normalmente se usa como multiclase (aunque no tenga softmax)\n",
        "        return \"multiclass_classification\"\n",
        "\n",
        "task = detect_task(out_dim, act_name)\n",
        "\n",
        "print(\"=== Detección automática ===\")\n",
        "print(\"output_shape:\", model.output_shape)\n",
        "print(\"last_activation:\", act_name)\n",
        "print(\"task_detected:\", task)\n",
        "\n",
        "# ----------------------------\n",
        "# 7) Post-procesamiento según tarea + guardar\n",
        "# ----------------------------\n",
        "out = new.copy()\n",
        "\n",
        "if task == \"regression\":\n",
        "    # y_raw: (n, 1) o (n,)\n",
        "    y_pred = np.asarray(y_raw).reshape(-1)\n",
        "    out[\"y_pred\"] = y_pred\n",
        "\n",
        "elif task == \"binary_classification\":\n",
        "    # y_raw: (n, 1) probabilidades\n",
        "    y_prob = np.asarray(y_raw).reshape(-1)\n",
        "    y_class = (y_prob >= threshold).astype(int)\n",
        "    out[\"y_prob\"] = y_prob\n",
        "    out[\"y_class\"] = y_class\n",
        "\n",
        "elif task == \"multiclass_classification\":\n",
        "    # y_raw: (n, C) probabilidades o scores\n",
        "    y_prob = np.asarray(y_raw)\n",
        "    if y_prob.ndim != 2 or y_prob.shape[1] != out_dim:\n",
        "        raise ValueError(f\"Salida inesperada para multiclase. shape={y_prob.shape}, out_dim={out_dim}\")\n",
        "\n",
        "    y_class = y_prob.argmax(axis=1).astype(int)\n",
        "\n",
        "    # Guardar probs por clase (columnas prob_c0, prob_c1, ...)\n",
        "    for j in range(out_dim):\n",
        "        out[f\"prob_c{j}\"] = y_prob[:, j]\n",
        "\n",
        "    out[\"y_class\"] = y_class\n",
        "\n",
        "else:\n",
        "    raise ValueError(f\"Tarea no soportada: {task}\")\n",
        "\n",
        "out.to_csv(OUT_PRED, index=False)\n",
        "print(f\"\\n✔ Predicciones guardadas en: {OUT_PRED}\")\n",
        "print(out.head())\n"
      ]
    }
  ]
}