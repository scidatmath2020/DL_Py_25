{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77557a43-21c1-4c00-b958-433bdd24c5dc",
   "metadata": {},
   "source": [
    "![imagenes](logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bb93ab-8456-49d9-b566-08ccd37fe643",
   "metadata": {},
   "source": [
    "# Clasificación multiclase\n",
    "\n",
    "En clasificación binaria todo gira alrededor de una sola pregunta: ¿pertenece o no a la clase positiva? \n",
    "\n",
    "Pero en muchos problemas reales la pregunta es más rica: ¿a cuál de varias clases pertenece? (tipo de flor, categoría de documento, tipo de falla, dígito escrito a mano, etc.).\n",
    "\n",
    "La clasificación multiclase consiste en asignar cada observación a una entre $K$ clases posibles. En deep learning, el modelo aprende regiones del espacio de características asociadas a cada clase, y produce una distribución de probabilidad sobre todas ellas.\n",
    "\n",
    "La diferencia con regresión no está en “qué tan profunda” es la red, sino en:\n",
    "\n",
    "- el tipo de variable objetivo (clase entre $K$),\n",
    "\n",
    "- la interpretación probabilística de la salida,\n",
    "\n",
    "- y la función de pérdida usada para entrenar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a138a4-5034-4c87-a85c-428f4bcd5953",
   "metadata": {},
   "source": [
    "## ¿Qué significa clasificar multiclase en una red neuronal?\n",
    "\n",
    "En un problema multiclase con $K$ clases, la red aprende una función\n",
    "\n",
    "$$f(\\boldsymbol{x})=(P(y=1|\\boldsymbol{x}),P(y=2|\\boldsymbol{x}),...,P(y=K|\\boldsymbol{x}))$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- cada componente es una probabilidad,\n",
    "\n",
    "- todas son no negativas y suman 1.\n",
    "\n",
    "En otras palabras: el modelo no “elige” directamente una clase; primero estima qué tan plausible es cada clase dada la entrada $\\boldsymbol{x}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e78462-0750-4471-80b6-f23afdc01147",
   "metadata": {},
   "source": [
    "## Capa de salida en clasificación multiclase\n",
    "\n",
    "En multiclase, la salida estándar es:\n",
    "- $K$ neuronas\n",
    "- Función de activación softmax\n",
    "\n",
    "La softmax transforma los scores (logits) en probabilidades $$\\hat{y}_k=\\frac{e^{z_k}}{\\sum_{j=1}^K e^{z_j}}$$\n",
    "\n",
    "Interpretación:\n",
    "- $\\hat{y}_k$ es la probabilidad asignada a la clase $k$\n",
    "- la predicción final usualmente es $\\mathrm{argmax}_k\\hat{y}_k$\n",
    "- y no hay un umbral único como en binaria: la decisión es “la clase con mayor probabilidad”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148f8b10-2bec-4bfb-a5ee-6ec96d6246e8",
   "metadata": {},
   "source": [
    "## Función de pérdida en clasificación multiclase\n",
    "\n",
    "La pérdida estándar es la entropía cruzada categórica (categorical cross-entropy). Si la etiqueta real está codificada como one-hot (vector con 1 en la clase correcta), la pérdida es: $$\\mathcal{L}=-\\sum_{k=1}^Ky_k\\log(\\hat{y}_k)$$\n",
    "\n",
    "Como sólo una componente $y_k$ vale 1 (la clase verdadera), esto equivale a:\n",
    "$$\\mathcal{L}=-\\log(\\hat{y}_{\\mbox{clase real}})$$\n",
    "\n",
    "Así, el modelo es castigado cuando asigna baja probabilidad a la clase correcta y la penalización crece mucho si **está seguro pero equivocado.**\n",
    "\n",
    "Durante el entrenamiento, minimizar esta pérdida equivale a maximizar la verosimilitud de las clases observadas bajo el modelo.\n",
    "\n",
    "## Regularización en clasificación multiclase\n",
    "\n",
    "El sobreajuste sigue siendo el enemigo: una red puede memorizar patrones accidentales y crear fronteras de decisión demasiado complejas.\n",
    "\n",
    "Las técnicas más usadas se mantienen:\n",
    "\n",
    "- L2 (weight decay): penaliza pesos grandes → decisiones más suaves y estables.\n",
    "\n",
    "- Dropout: obliga a redundancia interna → reduce dependencia de rutas específicas.\n",
    "\n",
    "- Early stopping: detiene el entrenamiento cuando el desempeño en validación deja de mejorar.\n",
    "\n",
    "En multiclase esto es especialmente importante porque pequeñas variaciones pueden cambiar el argmax y, con ello, la clase predicha."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3005883b-e17d-4779-a8df-d826f45a3c7d",
   "metadata": {},
   "source": [
    "## Métricas de evaluación en clasificación multiclase\n",
    "\n",
    "En multiclase, además del accuracy, suele interesar cómo se comporta el modelo **por clase**, porque no todas tienen la misma frecuencia o importancia.\n",
    "\n",
    "- **Accuracy:** proporción de aciertos globales.\n",
    "\n",
    "- **Matriz de confusión $K\\times K$:** muestra qué clases se confunden entre sí.\n",
    "\n",
    "- **Precision / Recall / F1 por clase**: evalúa desempeño clase a clase.\n",
    "\n",
    "- **Macro-F1:** promedio simple del F1 de cada clase (trata a todas las clases “igual”).\n",
    "\n",
    "- **Weighted-F1:** promedio ponderado por soporte (pesa más las clases frecuentes).\n",
    "\n",
    "La elección depende del contexto: no es lo mismo clasificar especies equilibradas que detectar una clase rara de falla crítica."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
