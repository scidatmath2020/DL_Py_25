{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hJP8hS5DaxJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "SEED = 7\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# --- Cargar CSV  ---\n",
        "#############################################\n",
        "#############################################\n",
        "#############################################\n",
        "\n",
        "df = pd.read_csv(\"\")\n",
        "\n",
        "#############################################\n",
        "#############################################\n",
        "#############################################\n",
        "\n",
        "df.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "ueh9_Del0SvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Elegir columna objetivo  ---\n",
        "\n",
        "#######################################################\n",
        "#######################################################\n",
        "#######################################################\n",
        "\n",
        "objetivo = \"\"\n",
        "\n",
        "#######################################################\n",
        "#######################################################\n",
        "#######################################################\n",
        "\n",
        "y = df[objetivo]\n",
        "X = df.drop(columns=[objetivo])"
      ],
      "metadata": {
        "id": "RejB_a6jDfHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Separación: train_full / test, luego train / val\n",
        "# =========================================================\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=SEED, stratify=y\n",
        "    )\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=0.20, random_state=SEED,  stratify=y_train_full\n",
        ")\n",
        "\n",
        "X_train.columns"
      ],
      "metadata": {
        "id": "nDBVB2JjDiGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Seleccionar columnas numéricas y categóricas  ---\n",
        "\n",
        "#######################################################\n",
        "#######################################################\n",
        "#######################################################\n",
        "\n",
        "cols_num = []\n",
        "cols_cat = []\n",
        "\n",
        "#######################################################\n",
        "#######################################################\n",
        "#######################################################\n",
        "\n",
        "# OJO: TRAIN debe salir de X_train (no de X_train_full)\n",
        "X_train_num = X_train[cols_num]\n",
        "X_train_cat = X_train[cols_cat]\n",
        "\n",
        "X_val_num = X_val[cols_num]\n",
        "X_val_cat = X_val[cols_cat]\n",
        "\n",
        "X_test_num = X_test[cols_num]\n",
        "X_test_cat = X_test[cols_cat]\n",
        "\n",
        "cols_cat"
      ],
      "metadata": {
        "id": "25Xf2ToQDkYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Seleccionar nominales y ordinales  ---\n",
        "\n",
        "#######################################################\n",
        "#######################################################\n",
        "#######################################################\n",
        "\n",
        "########## codificado de categoricas\n",
        "# Columnas\n",
        "cols_onehot  = []  # NOMINALES → One-Hot\n",
        "cols_ordinal = []\n",
        "\n",
        "# Categorías ordenadas para las ordinales (mismo orden que en cols_ordinal)\n",
        "categorias_ordinales = []  # lista de listas\n",
        "\n",
        "#######################################################\n",
        "#######################################################\n",
        "#######################################################\n",
        "\n",
        "preprocessor_cat = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\n",
        "            \"onehot\",\n",
        "            Pipeline(steps=[\n",
        "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "                (\"encoder\", OneHotEncoder(sparse_output=False, drop=None, handle_unknown=\"ignore\"))\n",
        "            ]),\n",
        "            cols_onehot\n",
        "        ),\n",
        "        (\n",
        "            \"ordinal\",\n",
        "            Pipeline(steps=[\n",
        "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "                (\"encoder\", OrdinalEncoder(\n",
        "                    categories=categorias_ordinales,\n",
        "                    handle_unknown=\"use_encoded_value\",\n",
        "                    unknown_value=-1\n",
        "                ))\n",
        "            ]),\n",
        "            cols_ordinal\n",
        "        ),\n",
        "    ],\n",
        "    remainder=\"drop\",\n",
        "    verbose_feature_names_out=False\n",
        ")\n",
        "\n",
        "preprocessor_cat.fit(X_train_cat)\n",
        "\n",
        "X_train_cat_proc = preprocessor_cat.transform(X_train_cat)\n",
        "X_val_cat_proc   = preprocessor_cat.transform(X_val_cat)\n",
        "X_test_cat_proc  = preprocessor_cat.transform(X_test_cat)\n",
        "\n",
        "cols_out_cat = list(preprocessor_cat.get_feature_names_out())\n",
        "\n",
        "# -----------------------------------------\n",
        "# Renombrar One-Hot a formato col___categoria\n",
        "# -----------------------------------------\n",
        "rename_map = {}\n",
        "if len(cols_onehot) > 0:\n",
        "    ohe = preprocessor_cat.named_transformers_[\"onehot\"].named_steps[\"encoder\"]\n",
        "    ohe_names = list(ohe.get_feature_names_out(cols_onehot))\n",
        "\n",
        "    for name in ohe_names:\n",
        "        for col in cols_onehot:\n",
        "            prefix = col + \"_\"\n",
        "            if name.startswith(prefix):\n",
        "                cat = name[len(prefix):]\n",
        "                rename_map[name] = f\"{col}___{cat}\"\n",
        "                break\n",
        "\n",
        "cols_out_cat = [rename_map.get(c, c) for c in cols_out_cat]\n",
        "\n",
        "df_train_cat_encode = pd.DataFrame(X_train_cat_proc, columns=cols_out_cat, index=X_train_cat.index)\n",
        "df_val_cat_encode   = pd.DataFrame(X_val_cat_proc,   columns=cols_out_cat, index=X_val_cat.index)\n",
        "df_test_cat_encode  = pd.DataFrame(X_test_cat_proc,  columns=cols_out_cat, index=X_test_cat.index)\n",
        "\n",
        "df_train_cat_encode"
      ],
      "metadata": {
        "id": "HpyEML2FDoEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Numéricas: imputación + escalado\n",
        "# =========================================================}\n",
        "# Asegurar que sean DataFrames y convertir a float32\n",
        "X_train_num = X_train_num.astype(np.float32)\n",
        "X_val_num = X_val_num.astype(np.float32)\n",
        "X_test_num = X_test_num.astype(np.float32)\n",
        "\n",
        "\n",
        "num_pipe = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "num_pipe.fit(X_train_num)\n",
        "\n",
        "T_train_num = num_pipe.transform(X_train_num)\n",
        "T_val_num   = num_pipe.transform(X_val_num)\n",
        "T_test_num  = num_pipe.transform(X_test_num)\n",
        "\n",
        "num_cols_out = X_train_num.columns\n",
        "\n",
        "T_train_num = pd.DataFrame(T_train_num, columns=num_cols_out, index=X_train_num.index)\n",
        "T_val_num   = pd.DataFrame(T_val_num,   columns=num_cols_out, index=X_val_num.index)\n",
        "T_test_num  = pd.DataFrame(T_test_num,  columns=num_cols_out, index=X_test_num.index)\n",
        "\n",
        "T_train_num"
      ],
      "metadata": {
        "id": "AHb_2-y0DwQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Unir numéricas + categóricas\n",
        "# =========================================================\n",
        "X_train_final_df = pd.concat([T_train_num, df_train_cat_encode], axis=1)\n",
        "X_val_final_df   = pd.concat([T_val_num,   df_val_cat_encode],   axis=1)\n",
        "X_test_final_df  = pd.concat([T_test_num,  df_test_cat_encode],  axis=1)\n",
        "\n",
        "# A numpy float32 para Keras (si se ocupa después)\n",
        "X_train_final = X_train_final_df.to_numpy(dtype=np.float32)\n",
        "X_val_final   = X_val_final_df.to_numpy(dtype=np.float32)\n",
        "X_test_final  = X_test_final_df.to_numpy(dtype=np.float32)\n",
        "\n",
        "# =========================================================\n",
        "# Devolver la columna objetivo (alineando por índice)\n",
        "# =========================================================\n",
        "train_final = X_train_final_df.copy()\n",
        "train_final[\"target\"] = y_train.loc[X_train_final_df.index].to_numpy()\n",
        "\n",
        "val_final = X_val_final_df.copy()\n",
        "val_final[\"target\"] = y_val.loc[X_val_final_df.index].to_numpy()\n",
        "\n",
        "test_final = X_test_final_df.copy()\n",
        "test_final[\"target\"] = y_test.loc[X_test_final_df.index].to_numpy()\n",
        "\n",
        "print(\"X_train_final:\", X_train_final.shape)\n",
        "print(\"X_val_final  :\", X_val_final.shape)\n",
        "print(\"X_test_final :\", X_test_final.shape)"
      ],
      "metadata": {
        "id": "dYVeKxHwDzJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# Guardar artefactos + datasets finales\n",
        "# =====================================================\n",
        "import os\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "ARTIFACT_DIR = \"artifacts_preprocesamiento\"\n",
        "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
        "\n",
        "# 1) Transformadores\n",
        "joblib.dump(num_pipe, f\"{ARTIFACT_DIR}/num_pipe.joblib\")\n",
        "joblib.dump(preprocessor_cat, f\"{ARTIFACT_DIR}/cat_preprocessor.joblib\")\n",
        "joblib.dump(list(X_train_final_df.columns), f\"{ARTIFACT_DIR}/feature_names.joblib\")\n",
        "\n",
        "# 2) Datasets finales CON target\n",
        "train_final.to_csv(f\"{ARTIFACT_DIR}/train_final.csv\", index=False)\n",
        "val_final.to_csv(f\"{ARTIFACT_DIR}/val_final.csv\", index=False)\n",
        "test_final.to_csv(f\"{ARTIFACT_DIR}/test_final.csv\", index=False)\n",
        "\n",
        "metadata = {\n",
        "    \"cols_num\": cols_num,\n",
        "    \"cols_cat\": cols_cat,\n",
        "    \"cols_onehot\": cols_onehot,\n",
        "    \"cols_ordinal\": cols_ordinal,\n",
        "    \"cat_out_cols\": list(X_train_final_df.columns[len(cols_num):]),  # solo las categóricas ya renombradas\n",
        "    \"feature_names\": list(X_train_final_df.columns)                  # num + cat, orden final\n",
        "}\n",
        "\n",
        "with open(f\"{ARTIFACT_DIR}/metadata_preprocesamiento.json\", \"w\") as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "\n",
        "print(\"Todos los artefactos y datasets fueron guardados correctamente.\")\n"
      ],
      "metadata": {
        "id": "7BS7NsluEZFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "ARTIFACT_DIR = \"artifacts_preprocesamiento\"\n",
        "ZIP_NAME = \"artifacts_preprocesamiento.zip\"\n",
        "\n",
        "with zipfile.ZipFile(ZIP_NAME, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
        "    for root, _, files in os.walk(ARTIFACT_DIR):\n",
        "        for f in files:\n",
        "            full_path = os.path.join(root, f)\n",
        "            z.write(full_path, arcname=os.path.relpath(full_path, ARTIFACT_DIR))\n",
        "\n",
        "print(\"ZIP final creado correctamente:\", ZIP_NAME)\n"
      ],
      "metadata": {
        "id": "5Gv67PRgOcJJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}